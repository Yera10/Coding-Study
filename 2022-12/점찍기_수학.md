# 프로그래머스 - 점 찍기


문제 링크 : [링크](https://school.programmers.co.kr/learn/courses/30/lessons/140107)<br>


### **Input**
- 두 양의 정수 k, d
- 좌표평면에 원점(0, 0)으로부터 x축 방향으로 a*k(a = 0, 1, 2, 3 ...), y축 방향으로 b*k(b = 0, 1, 2, 3 ...)만큼 떨어진 위치에 점을 찍습니다.
- 원점과 거리가 d를 넘는 위치에는 점을 찍지 않습니다

### **Output**
- 점이 총 몇 개 찍히는지 return 

### **입력과 출력 예**
| k	 | d | result |
|---|---|--------|
| 2 | 4	| 6 |
| 1 | 5	| 26 |


### **나의 풀이 코드**
통과 (771.78ms, 10.3MB)
```python
def solution(k, d):
    res = 0
    for x in range(0, d+1, k):
        y = (d**2 - x**2)**0.5
        res += (y//k + 1)
    return res
```
- $O(d//k)$<br>
- 그냥 좌표평면을 머리에 그리고, k로 사각형을 그리고, d로 원을 그린 후, 계산했다. 

통과 (730.66ms, 48.7MB)
```python
def solution(k, d):
    return sum([((d**2 - x**2)**0.5)//k + 1 for x in range(0, d+1, k)])
```
- list comprehension으로 쓰면 조금 더 빨라진다. 